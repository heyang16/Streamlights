{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "streamlights",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZ7IBhYKwLn5"
      },
      "source": [
        "#Install requirements\n",
        "!git clone https://github.com/1stDayHack/FDK.git\n",
        "!pip install detectron2 -f \\\n",
        "  https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.7/index.html\n",
        "!pip install streamlit -q\n",
        "!pip install -r /content/FDK/requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zpNYWiOeVm7"
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip -qq ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JpywtK_2dLK"
      },
      "source": [
        "#If you get IndexError: list index out of range, rerun the cell\n",
        "get_ipython().system_raw('./ngrok http 8501 &')\n",
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dY-DsQKu1Zx4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f456735-3745-46d5-c572-6011a6110e53"
      },
      "source": [
        "%%writefile streamlights.py\n",
        "import streamlit as st\n",
        "from time import time\n",
        "from time import sleep\n",
        "from torch.cuda import is_available\n",
        "import os\n",
        "import cv2\n",
        "import PIL\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from bokeh.plotting import figure\n",
        "from FDK.src.core.detect import Detector\n",
        "from FDK.src.core.utils.utils import cv2_to_pil\n",
        "\n",
        "\n",
        "def video_to_frames(file_name: str, step=1, frames=1000) -> list:\n",
        "    global vidcap\n",
        "    vidcap = cv2.VideoCapture(file_name)\n",
        "    success, image = vidcap.read()\n",
        "    image_list = []\n",
        "\n",
        "    while success:\n",
        "        image_list.append(image)\n",
        "\n",
        "        if len(image_list) >= frames:\n",
        "            break\n",
        "        \n",
        "        for _ in range(step):\n",
        "            success, image = vidcap.read()\n",
        "  \n",
        "    return image_list\n",
        "\n",
        "\n",
        "def frames_to_video(frames: list, filename=\"output\", fps=5, codec=\"DIVX\") -> cv2.VideoWriter:\n",
        "    video = cv2.VideoWriter(filename + \".mp4\", cv2.VideoWriter_fourcc(*codec), fps, frames[0].shape[0:2][::-1])\n",
        "\n",
        "    for frame in frames:\n",
        "        video.write(frame)\n",
        "  \n",
        "    return video\n",
        "\n",
        "CAR_TAG = 2\n",
        "\n",
        "class CountPredictions:\n",
        "    def __init__(self, frames: list, entry_rect: tuple, light_states={}, min_score=0.8, visualise=False, figsize=(10, 10)):\n",
        "        self.count = 0\n",
        "        self.frames = frames\n",
        "        self.redlight_counts = []\n",
        "        self.greenlight_counts = []\n",
        "        self.counts = []\n",
        "        self.light_states = light_states\n",
        "        self.visualise = visualise\n",
        "        self.visualised_frames = []\n",
        "        self.figsize = figsize\n",
        "        self.min_score = min_score\n",
        "        self.entry_rect = entry_rect\n",
        "  \n",
        "    def process_frame(self) -> float:\n",
        "        self.greenlight_counts = []\n",
        "        different_light_states = len(self.light_states) > 0\n",
        "        frame_count = len(self.frames)\n",
        "\n",
        "        if different_light_states:\n",
        "            was_green = list(self.light_states.values())[0]\n",
        "    \n",
        "        else:\n",
        "            was_green = True\n",
        "\n",
        "        if self.visualise:\n",
        "            self.visualised_frames = []\n",
        "\n",
        "        for i, frame in enumerate(self.frames):\n",
        "            output = detector.predict(frame)\n",
        "            instance = output[\"instances\"]\n",
        "\n",
        "            if self.visualise:\n",
        "                self.visualised_frames.append(detector.visualize(frame, output, figsize=self.figsize, noplot=True))\n",
        "\n",
        "            if different_light_states:\n",
        "                is_green = _locate_index_in_dict(self.light_states, i)\n",
        "      \n",
        "            else:\n",
        "                is_green = True\n",
        "\n",
        "            if i == 0:\n",
        "                self.greenlight_counts.append(count_cars_in_image(instance, self.min_score))\n",
        "\n",
        "            elif is_green:\n",
        "                if was_green:\n",
        "                    self.greenlight_counts.append(count_cars_in_image(instance, self.min_score))\n",
        "                    #self.greenlight_counts.append(_count_boxes_in_region([instance.pred_boxes[i] for i, tag in enumerate(instance.pred_classes) if tag == CAR_TAG and instance.scores[i] >= self.min_score], self.entry_rect[0], self.entry_rect[1]))\n",
        "      \n",
        "                else:\n",
        "                    self.count += count_cars_in_image(instance, self.min_score)\n",
        "            else:\n",
        "                self.redlight_counts.append(count_cars_in_image(instance, self.min_score))\n",
        "\n",
        "            self.counts.append(count_cars_in_image(instance, self.min_score))\n",
        "\n",
        "\n",
        "            was_green = is_green\n",
        "            yield i / frame_count\n",
        "  \n",
        "        last_x = 0\n",
        "        for x in self.greenlight_counts:\n",
        "            change = x - last_x\n",
        "            if change > 0:\n",
        "                self.count += change\n",
        "            last_x = x\n",
        "    \n",
        "        return 1.0\n",
        "\n",
        "def is_car_in_image(instance, min_score=0.8) -> bool:\n",
        "    for i, tag in instance.pred_classes:\n",
        "        if tag == CAR_TAG and instance.pred_scores[i] >= min_score:\n",
        "            return True\n",
        "\n",
        "    return False\n",
        "\n",
        "\n",
        "def count_cars_in_image(instance, min_score=0.8) -> int:\n",
        "    count = 0\n",
        "    for i, tag in enumerate(instance.pred_classes):\n",
        "        if tag == CAR_TAG and instance.scores[i] >= min_score:\n",
        "            count += 1\n",
        "    \n",
        "    return count\n",
        "\n",
        "\n",
        "def decreased_index(counts: list) -> list:\n",
        "    decreased = []\n",
        "    last_x = 0\n",
        "    for i, x in enumerate(counts):\n",
        "        if x - last_x < 0:\n",
        "            decreased.append(i)\n",
        "        last_x = x\n",
        "    return decreased\n",
        "\n",
        "\n",
        "def _locate_index_in_dict(dictionary: dict, index: int):\n",
        "    # if a dictionary is in the form {1: obj1, 6: obj2, 13: obj3 etc}\n",
        "    # this function will find the element which the index fits in\n",
        "    # so an index of 2 will return obj1 while 15 will return obj3, and 7 will return obj2\n",
        "    for idx in dictionary:\n",
        "        if index >= idx:\n",
        "            return dictionary[idx]\n",
        "\n",
        "\n",
        "# count cars\n",
        "def _count_boxes_in_region(boxes: list, top_left: tuple, bottom_right: tuple) -> int:\n",
        "    # Each box is in the format [x1, y1, x2, y2] probably\n",
        "    count = 0\n",
        "    for i, box in enumerate(boxes):\n",
        "        tensor = box.tensor[0]\n",
        "        if (top_left[0] <= float(tensor[0]) <= bottom_right[0] and top_left[1] <= float(tensor[1]) <= bottom_right[1]) or (top_left[0] <= float(tensor[2]) <= bottom_right[0] and top_left[1] <= float(tensor[3]) <= bottom_right[1]):\n",
        "            count += 1\n",
        "\n",
        "    return count\n",
        "\n",
        "#Streamlit\n",
        "\n",
        "\n",
        "#Head\n",
        "\n",
        "st.set_page_config(\n",
        "    page_title='Streamlights',\n",
        "    page_icon=':vertical_traffic_light:',\n",
        "    layout='centered',\n",
        "    initial_sidebar_state='expanded'\n",
        ")\n",
        "\n",
        "max_width = 80\n",
        "st.markdown(\n",
        "        f\"\"\"\n",
        "<style>\n",
        "    .reportview-container .main .block-container{{\n",
        "        max-width: {max_width}%;\n",
        "    }}\n",
        "</style>\n",
        "\"\"\",\n",
        "        unsafe_allow_html=True,\n",
        "    )\n",
        "\n",
        "\n",
        "st.title('Welcome to Streamlights')\n",
        "st.markdown('''Streamlights, a smart traffic light program that scans all incoming cars on the road and measures real-time traffic flow.<br/>\n",
        "Make valuable traffic data available for government road and public transportation planning.<br/>\n",
        "Information on red light runners made available for government action.<br/>\n",
        "When roads are empty, actuated signals can be sent to prolong green light signals at other roads in order to reduce vehicle idle time.''', unsafe_allow_html=True)\n",
        "\n",
        "#Body\n",
        "\n",
        "#Display instructions in sidebar\n",
        "instructions = st.sidebar.beta_expander('Instructions')\n",
        "instructions.subheader('Step 1.')\n",
        "instructions.write('Upload a video for 2 roads of the same junction each. Ensure that the video formats are either .mp4 or .avi')\n",
        "instructions.subheader('Step 2.')\n",
        "instructions.write('''When the videos are done uploading, select an fps ratio (output fps/original fps) and process the videos.\n",
        "The videos will be processed with Detectron2, and the number of cars per frame will be returned.\n",
        "This process may take awhile. To reduce processing time, run Google Colaboratory with a GPU hardware accelerator.''')\n",
        "instructions.subheader('Step 3.')\n",
        "instructions.write('View output videos and statistics')\n",
        "\n",
        "\n",
        "uploader = st.beta_expander('Upload Videos')\n",
        "uploader1 = uploader.beta_container()\n",
        "uploader2 = uploader.beta_container()\n",
        "\n",
        "video1 = uploader1.file_uploader('Upload a video of road 1')\n",
        "if video1 is not None:\n",
        "    try:\n",
        "        if video1.name.endswith('.mp4') or video1.endswith('.avi'):\n",
        "            uploader1.success('Uploaded')\n",
        "            open(video1.name, 'wb').write(video1.getvalue())\n",
        "            uploader1.video(video1.name)\n",
        "        else:\n",
        "            uploader1.error('File not supported, please use either .avi or .mp4 files instead')\n",
        "            video1 = None\n",
        "    except AttributeError:\n",
        "        uploader1.error('File not supported, please use either .avi or .mp4 files instead')\n",
        "\n",
        "video2 = uploader2.file_uploader('Upload a video of road 2')\n",
        "if video2 is not None:\n",
        "    try:\n",
        "        if video2.name.endswith('.mp4') or video2.endswith('.avi'):\n",
        "            uploader2.success('Uploaded')\n",
        "            open(video2.name, 'wb').write(video2.getvalue())\n",
        "            uploader2.video(video2.name)\n",
        "        else:\n",
        "            uploader2.error('File not supported, please use either .avi or .mp4 files instead')\n",
        "            video2 = None\n",
        "    except AttributeError:\n",
        "        uploader2.error('File not supported, please use either .avi or .mp4 files instead')\n",
        "\n",
        "\n",
        "if video1 is not None and video2 is not None:\n",
        "\n",
        "    if is_available():\n",
        "        device = uploader.selectbox('Select device to process videos', ('CPU', 'GPU'), index=1)\n",
        "        if device == 'CPU':\n",
        "            device = 'cpu'\n",
        "        else:\n",
        "            device = 'cuda'\n",
        "    else:\n",
        "        device = 'cpu'\n",
        "\n",
        "    # Instantiate detector\n",
        "    detector = Detector(name=\"MyDet\", device=device)\n",
        "\n",
        "    #fps ratio slider\n",
        "    fps_ratio = uploader.slider('Select fps ratio', min_value=0.1, max_value=1.0)\n",
        "    uploader.write('Note: a greater fps ratio would yield smoother videos, but would take longer to process')\n",
        "\n",
        "    if uploader.button('Process videos'):\n",
        "\n",
        "        (major_ver, minor_ver, subminor_ver) = (cv2.__version__).split('.')\n",
        "\n",
        "        #Process video1\n",
        "        video1_frames = video_to_frames(video1.name, int(1 / fps_ratio))\n",
        "        if int(major_ver)  < 3 :\n",
        "            fps1 = vidcap.get(cv2.cv.CV_CAP_PROP_FPS)\n",
        "        else :\n",
        "            fps1 = vidcap.get(cv2.CAP_PROP_FPS)\n",
        "        video1_counter = CountPredictions(video1_frames, ((0, 0), video1_frames[0].shape[0:2][::-1]), light_states={0: False}, visualise=True)\n",
        "\n",
        "        #Progress bar\n",
        "        t = time()\n",
        "        progress_container = uploader.empty()\n",
        "        progress_container.write('Processing video 1...')\n",
        "        progress_bar = uploader.empty()\n",
        "        bar1 = progress_bar.progress(0)\n",
        "        secs_left = uploader.empty()\n",
        "        for progress in video1_counter.process_frame():\n",
        "            if progress > 0:\n",
        "                bar1.progress(progress)\n",
        "                seconds = int((time() - t) * (1 / progress - 1))\n",
        "                if seconds == 1:\n",
        "                    secs_left.write(str(seconds) + \" second remaining\")\n",
        "                else:\n",
        "                    secs_left.write(str(seconds) + \" seconds remaining\")\n",
        "\n",
        "        #Process video2\n",
        "        video2_frames = video_to_frames(video2.name, int(1 / fps_ratio))\n",
        "        if int(major_ver)  < 3 :\n",
        "            fps2 = vidcap.get(cv2.cv.CV_CAP_PROP_FPS)\n",
        "        else :\n",
        "            fps2 = vidcap.get(cv2.CAP_PROP_FPS)\n",
        "        video2_counter = CountPredictions(video2_frames, ((0, 0), video2_frames[0].shape[0:2][::-1]), light_states={0: False}, visualise=True)\n",
        "\n",
        "        #Progress bar\n",
        "        t = time()\n",
        "        progress_container.write('Processing video 2...')\n",
        "        bar2 = progress_bar.progress(0)\n",
        "        for progress in video2_counter.process_frame():\n",
        "            if progress > 0:\n",
        "                bar2.progress(progress)\n",
        "                seconds = int((time() - t) * (1 / progress - 1))\n",
        "                if seconds == 1:\n",
        "                    secs_left.write(str(seconds) + \" second remaining\")\n",
        "                elif seconds == 0:\n",
        "                    secs_left.write(\"Generating data...\")\n",
        "                else:\n",
        "                    secs_left.write(str(seconds) + \" seconds remaining\")\n",
        "        progress_container.empty()\n",
        "        secs_left.empty()\n",
        "        progress_bar.empty()\n",
        "\n",
        "        #Convert processed frames to video\n",
        "        video1_processed = frames_to_video(video1_counter.visualised_frames, filename='video1_processed', fps=fps1 * fps_ratio, codec='DIVX')\n",
        "        video2_processed = frames_to_video(video2_counter.visualised_frames, filename='video2_processed', fps=fps2 * fps_ratio, codec='DIVX')\n",
        "        video1_processed.release()\n",
        "        video2_processed.release()\n",
        "\n",
        "        #Convert video fourcc codec to X264\n",
        "        os.system('ffmpeg -y -i video1_processed.mp4 -vcodec libx264 output1.mp4')\n",
        "        os.system('ffmpeg -y -i video2_processed.mp4 -vcodec libx264 output2.mp4')\n",
        "\n",
        "\n",
        "        #Display videos\n",
        "        video_displayer = st.beta_expander('Output videos')\n",
        "\n",
        "        video_displayer.subheader('Road 1')\n",
        "        video_displayer.video('output1.mp4')\n",
        "\n",
        "        video_displayer.subheader('Road 2')\n",
        "        video_displayer.video('output2.mp4')\n",
        "\n",
        "        #Display red light runners\n",
        "        red_runners = st.beta_expander('Red light runners')\n",
        "\n",
        "        red_runners.markdown('For demonstration purposes, we assume that the traffic lights are red for the entire duration of the video for both roads.')\n",
        "        red_runners.markdown('In the future, this program can be synchronized with the traffic light states, as well as recognize and record the car plates of red light runners')\n",
        "        red_runners.markdown('As of now, the right light runners are the cars at the bottommost of each image.')\n",
        "\n",
        "        runners1 = (decreased_index(video1_counter.redlight_counts))\n",
        "        runners2 = (decreased_index(video2_counter.redlight_counts))\n",
        "        road1_runners = red_runners.beta_container()\n",
        "        road2_runners = red_runners.beta_container()\n",
        "\n",
        "        road1_runners.subheader('Road 1')\n",
        "        road1_col1, road1_col2, road1_col3, road1_col4 = road1_runners.beta_columns(4)\n",
        "        road1_column_list = [road1_col1, road1_col2, road1_col3, road1_col4]\n",
        "        for i, index in enumerate(runners1):\n",
        "            road1_column_list[i % 4].image(video1_counter.visualised_frames[index], use_column_width=True)\n",
        "\n",
        "        road2_runners.subheader('Road 2')\n",
        "        road2_col1, road2_col2, road2_col3, road2_col4 = road2_runners.beta_columns(4)\n",
        "        road2_column_list = [road2_col1, road2_col2, road2_col3, road2_col4]\n",
        "        for i, index in enumerate(runners2):\n",
        "            road2_column_list[i % 4].image(video2_counter.visualised_frames[index], use_column_width=True)\n",
        "\n",
        "        #Display data and statistics\n",
        "        data_section = st.beta_expander('Data and Statistics')\n",
        "        \n",
        "        x1 = []\n",
        "        x2 = []\n",
        "        y1 = video1_counter.counts\n",
        "        y2 = video2_counter.counts\n",
        "        for i in range(len(video1_counter.counts)):\n",
        "            x1.append(i / (fps1 * fps_ratio))\n",
        "        for i in range(len(video2_counter.counts)):\n",
        "            x2.append(i / (fps2 * fps_ratio))\n",
        "\n",
        "        p = figure(title='Graph of amount of cars in frame against time', x_axis_label='Time / seconds', y_axis_label='Amount of cars in frame')\n",
        "        p.line(x1, y1, legend='Road 1', line_width=2, line_color='red')\n",
        "        p.line(x2, y2, legend='Road 2', line_width=2, line_color='blue')\n",
        "        data_section.bokeh_chart(p, use_container_width=True)\n",
        "\n",
        "        data_section.markdown('Average number of cars per frame for road 1: ' + '**' + str(round(sum(video1_counter.counts) / len(video1_counter.counts), 1)) + '**')\n",
        "        data_section.markdown('Average number of cars per frame for road 2: ' + '**' + str(round(sum(video2_counter.counts) / len(video2_counter.counts), 1)) + '**')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting streamlights.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zWZPKREx1P6"
      },
      "source": [
        "!streamlit run streamlights.py"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}